

import numpy as np
from numpy import linalg
import pandas as pd

# function to help print the numpy arrays in a cleaner manner
def print_numpy(ndarray):
    with np.printoptions(precision=4, suppress=True, formatter={'float': '{:0.4f}'.format}, linewidth=100):
        print(ndarray)
        
        
def scale_dataframe(dataframe: pd.DataFrame(), return_as_dataframe: bool = False):
    """Scales/normalizes the data such that each column has zero mean and unit variance"""
    
    # convert dataframe to array
    ndarray = np.asanyarray(dataframe)
    
    # calculate the mean and standard deviations of the columns
    means = ndarray.mean(axis = 0, keepdims = True)
    std_devs = ndarray.std(axis = 0, ddof = 1, keepdims = True)        
    
    # subtract mean and divide by std. dev. element-wise
    scaled_array = (ndarray - means) / std_devs
    
    # return the scaled data in the appropriate form
    if return_as_dataframe:
        return pd.DataFrame(data = scaled_array, columns = dataframe.columns)
    else:
        return scaled_array
    
def calculate_covariance_matrix(ndarray): 
    """Since we are handling scaled data with zero mean, when computing the covariance matrix
    there is no need to subtract the mean from the data points. We just need the dot product of 
    the transposed matrix with itself, and each element of the product divided by the number of samples.
    Transpose has dimensions [n_features, n_samples].
    Non-transpose matrix has dimensions [n_samples, n_features].
    The dot product gives [n_features, n_features] shape."""
    
    return (np.dot(ndarray.T, ndarray) * np.true_divide(1, ndarray.shape[0])).squeeze()



def pca(df: pd.DataFrame)
    
    print('\nStarting dataset:')
    print(df.head())
    
    # scale the data into a numpy array, further manipulation is easier with numpy    
    dataset_scaled_array = scale_dataframe(df)
    
    # also get dataframe version to view the scaled data
    dataset_scaled = pd.DataFrame(data = dataset_scaled_array, columns = dataset.columns)
    
    print('\nScaled dataset:')
    print(dataset_scaled.head())
        
    # calculate the covariance matrix
    covariance_matrix = calculate_covariance_matrix(dataset_scaled_array)
    print('\nCovariance matrix:')
    print_numpy(covariance_matrix)
        
    # get the eigenvectors and their coresponding eigenvalues with the help of numpy
    # each column of the _____ matrix is an eigenvector and the value with the same index
    # in the eignevcalues array is the magnitude that the space is stretched in the direction
    # of the eigenvector
    eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)
    print('\nEigenvalues:')
    print_numpy(eigenvalues)
    print('\nEigenvectors: ')
    print_numpy(eigenvectors)
        
    explained_variances = []
    for i in range(len(eigenvalues)):
        explained_variances.append(eigenvalues[i] / np.sum(eigenvalues))

    print('Explained variances of the principal components:')
    print_numpy(np.asarray(explained_variances))

